// Code generated by pggen. DO NOT EDIT.

package db

import (
	"context"
	"fmt"
	"github.com/jackc/pgconn"
	"github.com/jackc/pgtype"
	"github.com/jackc/pgx/v4"
)

// Querier is a typesafe Go interface backed by SQL queries.
//
// Methods ending with Batch enqueue a query to run later in a pgx.Batch. After
// calling SendBatch on pgx.Conn, pgxpool.Pool, or pgx.Tx, use the Scan methods
// to parse the results.
type Querier interface {
	GetScreenshotByPath(ctx context.Context, directoryAlias string, filename string) (GetScreenshotByPathRow, error)
	// GetScreenshotByPathBatch enqueues a GetScreenshotByPath query into batch to be executed
	// later by the batch.
	GetScreenshotByPathBatch(batch *pgx.Batch, directoryAlias string, filename string)
	// GetScreenshotByPathScan scans the result of an executed GetScreenshotByPathBatch query.
	GetScreenshotByPathScan(results pgx.BatchResults) (GetScreenshotByPathRow, error)

	GetScreenshotByID(ctx context.Context, id int) (GetScreenshotByIDRow, error)
	// GetScreenshotByIDBatch enqueues a GetScreenshotByID query into batch to be executed
	// later by the batch.
	GetScreenshotByIDBatch(batch *pgx.Batch, id int)
	// GetScreenshotByIDScan scans the result of an executed GetScreenshotByIDBatch query.
	GetScreenshotByIDScan(results pgx.BatchResults) (GetScreenshotByIDRow, error)

	CreateScreenshot(ctx context.Context, params CreateScreenshotParams) (CreateScreenshotRow, error)
	// CreateScreenshotBatch enqueues a CreateScreenshot query into batch to be executed
	// later by the batch.
	CreateScreenshotBatch(batch *pgx.Batch, params CreateScreenshotParams)
	// CreateScreenshotScan scans the result of an executed CreateScreenshotBatch query.
	CreateScreenshotScan(results pgx.BatchResults) (CreateScreenshotRow, error)

	GetAllScreenshots(ctx context.Context) ([]GetAllScreenshotsRow, error)
	// GetAllScreenshotsBatch enqueues a GetAllScreenshots query into batch to be executed
	// later by the batch.
	GetAllScreenshotsBatch(batch *pgx.Batch)
	// GetAllScreenshotsScan scans the result of an executed GetAllScreenshotsBatch query.
	GetAllScreenshotsScan(results pgx.BatchResults) ([]GetAllScreenshotsRow, error)

	CreateBlock(ctx context.Context, params CreateBlockParams) (pgconn.CommandTag, error)
	// CreateBlockBatch enqueues a CreateBlock query into batch to be executed
	// later by the batch.
	CreateBlockBatch(batch *pgx.Batch, params CreateBlockParams)
	// CreateBlockScan scans the result of an executed CreateBlockBatch query.
	CreateBlockScan(results pgx.BatchResults) (pgconn.CommandTag, error)

	CountDirectoriesByAlias(ctx context.Context) ([]CountDirectoriesByAliasRow, error)
	// CountDirectoriesByAliasBatch enqueues a CountDirectoriesByAlias query into batch to be executed
	// later by the batch.
	CountDirectoriesByAliasBatch(batch *pgx.Batch)
	// CountDirectoriesByAliasScan scans the result of an executed CountDirectoriesByAliasBatch query.
	CountDirectoriesByAliasScan(results pgx.BatchResults) ([]CountDirectoriesByAliasRow, error)

	// https://www.postgresql.org/docs/current/pgtrgm.html
	SearchScreenshots(ctx context.Context, params SearchScreenshotsParams) ([]SearchScreenshotsRow, error)
	// SearchScreenshotsBatch enqueues a SearchScreenshots query into batch to be executed
	// later by the batch.
	SearchScreenshotsBatch(batch *pgx.Batch, params SearchScreenshotsParams)
	// SearchScreenshotsScan scans the result of an executed SearchScreenshotsBatch query.
	SearchScreenshotsScan(results pgx.BatchResults) ([]SearchScreenshotsRow, error)
}

type DBQuerier struct {
	conn genericConn
}

var _ Querier = &DBQuerier{}

// genericConn is a connection to a Postgres database. This is usually backed by
// *pgx.Conn, pgx.Tx, or *pgxpool.Pool.
type genericConn interface {
	// Query executes sql with args. If there is an error the returned Rows will
	// be returned in an error state. So it is allowed to ignore the error
	// returned from Query and handle it in Rows.
	Query(ctx context.Context, sql string, args ...interface{}) (pgx.Rows, error)

	// QueryRow is a convenience wrapper over Query. Any error that occurs while
	// querying is deferred until calling Scan on the returned Row. That Row will
	// error with pgx.ErrNoRows if no rows are returned.
	QueryRow(ctx context.Context, sql string, args ...interface{}) pgx.Row

	// Exec executes sql. sql can be either a prepared statement name or an SQL
	// string. arguments should be referenced positionally from the sql string
	// as $1, $2, etc.
	Exec(ctx context.Context, sql string, arguments ...interface{}) (pgconn.CommandTag, error)
}

// NewQuerier creates a DBQuerier that implements Querier. conn is typically
// *pgx.Conn, pgx.Tx, or *pgxpool.Pool.
func NewQuerier(conn genericConn) *DBQuerier {
	return &DBQuerier{
		conn: conn,
	}
}

// WithTx creates a new DBQuerier that uses the transaction to run all queries.
func (q *DBQuerier) WithTx(tx pgx.Tx) (*DBQuerier, error) {
	return &DBQuerier{conn: tx}, nil
}

// ignoredOID means we don't know or care about the OID for a type. This is okay
// because pgx only uses the OID to encode values and lookup a decoder. We only
// use ignoredOID for decoding and we always specify a concrete decoder for scan
// methods.
const ignoredOID = 0

// Blocks represents the Postgres composite type "blocks".
type Blocks struct {
	ID           pgtype.Int4 `json:"id"`
	ScreenshotID pgtype.Int8 `json:"screenshot_id"`
	Index        pgtype.Int2 `json:"index"`
	MinX         pgtype.Int2 `json:"min_x"`
	MinY         pgtype.Int2 `json:"min_y"`
	MaxX         pgtype.Int2 `json:"max_x"`
	MaxY         pgtype.Int2 `json:"max_y"`
	Body         pgtype.Text `json:"body"`
}

const getScreenshotByPathSQL = `select
    *
from
    screenshots
where
    directory_alias = $1
    and filename = $2
limit 1;`

type GetScreenshotByPathRow struct {
	ID             pgtype.Int8      `json:"id"`
	Timestamp      pgtype.Timestamp `json:"timestamp"`
	DirectoryAlias pgtype.Text      `json:"directory_alias"`
	Filename       pgtype.Text      `json:"filename"`
	DimWidth       pgtype.Int4      `json:"dim_width"`
	DimHeight      pgtype.Int4      `json:"dim_height"`
	DominantColour pgtype.Text      `json:"dominant_colour"`
	Blurhash       pgtype.Text      `json:"blurhash"`
}

// GetScreenshotByPath implements Querier.GetScreenshotByPath.
func (q *DBQuerier) GetScreenshotByPath(ctx context.Context, directoryAlias string, filename string) (GetScreenshotByPathRow, error) {
	row := q.conn.QueryRow(ctx, getScreenshotByPathSQL, directoryAlias, filename)
	var item GetScreenshotByPathRow
	if err := row.Scan(&item.ID, &item.Timestamp, &item.DirectoryAlias, &item.Filename, &item.DimWidth, &item.DimHeight, &item.DominantColour, &item.Blurhash); err != nil {
		return item, fmt.Errorf("query GetScreenshotByPath: %w", err)
	}
	return item, nil
}

// GetScreenshotByPathBatch implements Querier.GetScreenshotByPathBatch.
func (q *DBQuerier) GetScreenshotByPathBatch(batch *pgx.Batch, directoryAlias string, filename string) {
	batch.Queue(getScreenshotByPathSQL, directoryAlias, filename)
}

// GetScreenshotByPathScan implements Querier.GetScreenshotByPathScan.
func (q *DBQuerier) GetScreenshotByPathScan(results pgx.BatchResults) (GetScreenshotByPathRow, error) {
	row := results.QueryRow()
	var item GetScreenshotByPathRow
	if err := row.Scan(&item.ID, &item.Timestamp, &item.DirectoryAlias, &item.Filename, &item.DimWidth, &item.DimHeight, &item.DominantColour, &item.Blurhash); err != nil {
		return item, fmt.Errorf("scan GetScreenshotByPathBatch row: %w", err)
	}
	return item, nil
}

const getScreenshotByIDSQL = `select
    *
from
    screenshots
where
    id = $1
limit 1;`

type GetScreenshotByIDRow struct {
	ID             pgtype.Int8      `json:"id"`
	Timestamp      pgtype.Timestamp `json:"timestamp"`
	DirectoryAlias pgtype.Text      `json:"directory_alias"`
	Filename       pgtype.Text      `json:"filename"`
	DimWidth       pgtype.Int4      `json:"dim_width"`
	DimHeight      pgtype.Int4      `json:"dim_height"`
	DominantColour pgtype.Text      `json:"dominant_colour"`
	Blurhash       pgtype.Text      `json:"blurhash"`
}

// GetScreenshotByID implements Querier.GetScreenshotByID.
func (q *DBQuerier) GetScreenshotByID(ctx context.Context, id int) (GetScreenshotByIDRow, error) {
	row := q.conn.QueryRow(ctx, getScreenshotByIDSQL, id)
	var item GetScreenshotByIDRow
	if err := row.Scan(&item.ID, &item.Timestamp, &item.DirectoryAlias, &item.Filename, &item.DimWidth, &item.DimHeight, &item.DominantColour, &item.Blurhash); err != nil {
		return item, fmt.Errorf("query GetScreenshotByID: %w", err)
	}
	return item, nil
}

// GetScreenshotByIDBatch implements Querier.GetScreenshotByIDBatch.
func (q *DBQuerier) GetScreenshotByIDBatch(batch *pgx.Batch, id int) {
	batch.Queue(getScreenshotByIDSQL, id)
}

// GetScreenshotByIDScan implements Querier.GetScreenshotByIDScan.
func (q *DBQuerier) GetScreenshotByIDScan(results pgx.BatchResults) (GetScreenshotByIDRow, error) {
	row := results.QueryRow()
	var item GetScreenshotByIDRow
	if err := row.Scan(&item.ID, &item.Timestamp, &item.DirectoryAlias, &item.Filename, &item.DimWidth, &item.DimHeight, &item.DominantColour, &item.Blurhash); err != nil {
		return item, fmt.Errorf("scan GetScreenshotByIDBatch row: %w", err)
	}
	return item, nil
}

const createScreenshotSQL = `insert into screenshots (id, timestamp, directory_alias, filename, dim_width, dim_height, dominant_colour, blurhash)
    values ($1, $2, $3, $4, $5, $6, $7, $8)
returning
    *;`

type CreateScreenshotParams struct {
	ID             int
	Timestamp      pgtype.Timestamp
	DirectoryAlias string
	Filename       string
	DimWidth       int32
	DimHeight      int32
	DominantColour string
	Blurhash       string
}

type CreateScreenshotRow struct {
	ID             int              `json:"id"`
	Timestamp      pgtype.Timestamp `json:"timestamp"`
	DirectoryAlias string           `json:"directory_alias"`
	Filename       string           `json:"filename"`
	DimWidth       int32            `json:"dim_width"`
	DimHeight      int32            `json:"dim_height"`
	DominantColour string           `json:"dominant_colour"`
	Blurhash       string           `json:"blurhash"`
}

// CreateScreenshot implements Querier.CreateScreenshot.
func (q *DBQuerier) CreateScreenshot(ctx context.Context, params CreateScreenshotParams) (CreateScreenshotRow, error) {
	row := q.conn.QueryRow(ctx, createScreenshotSQL, params.ID, params.Timestamp, params.DirectoryAlias, params.Filename, params.DimWidth, params.DimHeight, params.DominantColour, params.Blurhash)
	var item CreateScreenshotRow
	if err := row.Scan(&item.ID, &item.Timestamp, &item.DirectoryAlias, &item.Filename, &item.DimWidth, &item.DimHeight, &item.DominantColour, &item.Blurhash); err != nil {
		return item, fmt.Errorf("query CreateScreenshot: %w", err)
	}
	return item, nil
}

// CreateScreenshotBatch implements Querier.CreateScreenshotBatch.
func (q *DBQuerier) CreateScreenshotBatch(batch *pgx.Batch, params CreateScreenshotParams) {
	batch.Queue(createScreenshotSQL, params.ID, params.Timestamp, params.DirectoryAlias, params.Filename, params.DimWidth, params.DimHeight, params.DominantColour, params.Blurhash)
}

// CreateScreenshotScan implements Querier.CreateScreenshotScan.
func (q *DBQuerier) CreateScreenshotScan(results pgx.BatchResults) (CreateScreenshotRow, error) {
	row := results.QueryRow()
	var item CreateScreenshotRow
	if err := row.Scan(&item.ID, &item.Timestamp, &item.DirectoryAlias, &item.Filename, &item.DimWidth, &item.DimHeight, &item.DominantColour, &item.Blurhash); err != nil {
		return item, fmt.Errorf("scan CreateScreenshotBatch row: %w", err)
	}
	return item, nil
}

const getAllScreenshotsSQL = `select
    *
from
    screenshots;`

type GetAllScreenshotsRow struct {
	ID             pgtype.Int8      `json:"id"`
	Timestamp      pgtype.Timestamp `json:"timestamp"`
	DirectoryAlias pgtype.Text      `json:"directory_alias"`
	Filename       pgtype.Text      `json:"filename"`
	DimWidth       pgtype.Int4      `json:"dim_width"`
	DimHeight      pgtype.Int4      `json:"dim_height"`
	DominantColour pgtype.Text      `json:"dominant_colour"`
	Blurhash       pgtype.Text      `json:"blurhash"`
}

// GetAllScreenshots implements Querier.GetAllScreenshots.
func (q *DBQuerier) GetAllScreenshots(ctx context.Context) ([]GetAllScreenshotsRow, error) {
	rows, err := q.conn.Query(ctx, getAllScreenshotsSQL)
	if err != nil {
		return nil, fmt.Errorf("query GetAllScreenshots: %w", err)
	}
	defer rows.Close()
	items := []GetAllScreenshotsRow{}
	for rows.Next() {
		var item GetAllScreenshotsRow
		if err := rows.Scan(&item.ID, &item.Timestamp, &item.DirectoryAlias, &item.Filename, &item.DimWidth, &item.DimHeight, &item.DominantColour, &item.Blurhash); err != nil {
			return nil, fmt.Errorf("scan GetAllScreenshots row: %w", err)
		}
		items = append(items, item)
	}
	if err := rows.Err(); err != nil {
		return nil, fmt.Errorf("close GetAllScreenshots rows: %w", err)
	}
	return items, err
}

// GetAllScreenshotsBatch implements Querier.GetAllScreenshotsBatch.
func (q *DBQuerier) GetAllScreenshotsBatch(batch *pgx.Batch) {
	batch.Queue(getAllScreenshotsSQL)
}

// GetAllScreenshotsScan implements Querier.GetAllScreenshotsScan.
func (q *DBQuerier) GetAllScreenshotsScan(results pgx.BatchResults) ([]GetAllScreenshotsRow, error) {
	rows, err := results.Query()
	if err != nil {
		return nil, fmt.Errorf("query GetAllScreenshotsBatch: %w", err)
	}
	defer rows.Close()
	items := []GetAllScreenshotsRow{}
	for rows.Next() {
		var item GetAllScreenshotsRow
		if err := rows.Scan(&item.ID, &item.Timestamp, &item.DirectoryAlias, &item.Filename, &item.DimWidth, &item.DimHeight, &item.DominantColour, &item.Blurhash); err != nil {
			return nil, fmt.Errorf("scan GetAllScreenshotsBatch row: %w", err)
		}
		items = append(items, item)
	}
	if err := rows.Err(); err != nil {
		return nil, fmt.Errorf("close GetAllScreenshotsBatch rows: %w", err)
	}
	return items, err
}

const createBlockSQL = `insert into blocks (screenshot_id, index, min_x, min_y, max_x, max_y, body)
        values ($1, $2, $3, $4, $5, $6, $7);`

type CreateBlockParams struct {
	ScreenshotID int
	Index        int16
	MinX         int16
	MinY         int16
	MaxX         int16
	MaxY         int16
	Body         string
}

// CreateBlock implements Querier.CreateBlock.
func (q *DBQuerier) CreateBlock(ctx context.Context, params CreateBlockParams) (pgconn.CommandTag, error) {
	cmdTag, err := q.conn.Exec(ctx, createBlockSQL, params.ScreenshotID, params.Index, params.MinX, params.MinY, params.MaxX, params.MaxY, params.Body)
	if err != nil {
		return cmdTag, fmt.Errorf("exec query CreateBlock: %w", err)
	}
	return cmdTag, err
}

// CreateBlockBatch implements Querier.CreateBlockBatch.
func (q *DBQuerier) CreateBlockBatch(batch *pgx.Batch, params CreateBlockParams) {
	batch.Queue(createBlockSQL, params.ScreenshotID, params.Index, params.MinX, params.MinY, params.MaxX, params.MaxY, params.Body)
}

// CreateBlockScan implements Querier.CreateBlockScan.
func (q *DBQuerier) CreateBlockScan(results pgx.BatchResults) (pgconn.CommandTag, error) {
	cmdTag, err := results.Exec()
	if err != nil {
		return cmdTag, fmt.Errorf("exec CreateBlockBatch: %w", err)
	}
	return cmdTag, err
}

const countDirectoriesByAliasSQL = `select
    directory_alias,
    count(1)
from
    screenshots
group by
    directory_alias;`

type CountDirectoriesByAliasRow struct {
	DirectoryAlias pgtype.Text `json:"directory_alias"`
	Count          pgtype.Int8 `json:"count"`
}

// CountDirectoriesByAlias implements Querier.CountDirectoriesByAlias.
func (q *DBQuerier) CountDirectoriesByAlias(ctx context.Context) ([]CountDirectoriesByAliasRow, error) {
	rows, err := q.conn.Query(ctx, countDirectoriesByAliasSQL)
	if err != nil {
		return nil, fmt.Errorf("query CountDirectoriesByAlias: %w", err)
	}
	defer rows.Close()
	items := []CountDirectoriesByAliasRow{}
	for rows.Next() {
		var item CountDirectoriesByAliasRow
		if err := rows.Scan(&item.DirectoryAlias, &item.Count); err != nil {
			return nil, fmt.Errorf("scan CountDirectoriesByAlias row: %w", err)
		}
		items = append(items, item)
	}
	if err := rows.Err(); err != nil {
		return nil, fmt.Errorf("close CountDirectoriesByAlias rows: %w", err)
	}
	return items, err
}

// CountDirectoriesByAliasBatch implements Querier.CountDirectoriesByAliasBatch.
func (q *DBQuerier) CountDirectoriesByAliasBatch(batch *pgx.Batch) {
	batch.Queue(countDirectoriesByAliasSQL)
}

// CountDirectoriesByAliasScan implements Querier.CountDirectoriesByAliasScan.
func (q *DBQuerier) CountDirectoriesByAliasScan(results pgx.BatchResults) ([]CountDirectoriesByAliasRow, error) {
	rows, err := results.Query()
	if err != nil {
		return nil, fmt.Errorf("query CountDirectoriesByAliasBatch: %w", err)
	}
	defer rows.Close()
	items := []CountDirectoriesByAliasRow{}
	for rows.Next() {
		var item CountDirectoriesByAliasRow
		if err := rows.Scan(&item.DirectoryAlias, &item.Count); err != nil {
			return nil, fmt.Errorf("scan CountDirectoriesByAliasBatch row: %w", err)
		}
		items = append(items, item)
	}
	if err := rows.Err(); err != nil {
		return nil, fmt.Errorf("close CountDirectoriesByAliasBatch rows: %w", err)
	}
	return items, err
}

const searchScreenshotsSQL = `select
    screenshots.*,
    array_agg(blocks order by blocks.index) as blocks,
    avg(similarity (blocks.body, $1)) as similarity
from
    screenshots
    join blocks on blocks.screenshot_id = screenshots.id
where
    blocks.body % $1
group by
    screenshots.id
order by
    similarity desc
limit $2 offset $3;`

type SearchScreenshotsParams struct {
	Body   string
	Limit  int
	Offset int
}

type SearchScreenshotsRow struct {
	ID             pgtype.Int8      `json:"id"`
	Timestamp      pgtype.Timestamp `json:"timestamp"`
	DirectoryAlias pgtype.Text      `json:"directory_alias"`
	Filename       pgtype.Text      `json:"filename"`
	DimWidth       pgtype.Int4      `json:"dim_width"`
	DimHeight      pgtype.Int4      `json:"dim_height"`
	DominantColour pgtype.Text      `json:"dominant_colour"`
	Blurhash       pgtype.Text      `json:"blurhash"`
	Blocks         []Blocks         `json:"blocks"`
	Similarity     pgtype.Float8    `json:"similarity"`
}

// SearchScreenshots implements Querier.SearchScreenshots.
func (q *DBQuerier) SearchScreenshots(ctx context.Context, params SearchScreenshotsParams) ([]SearchScreenshotsRow, error) {
	rows, err := q.conn.Query(ctx, searchScreenshotsSQL, params.Body, params.Limit, params.Offset)
	if err != nil {
		return nil, fmt.Errorf("query SearchScreenshots: %w", err)
	}
	defer rows.Close()
	items := []SearchScreenshotsRow{}
	blocksRow, _ := pgtype.NewCompositeTypeValues("blocks", []pgtype.CompositeTypeField{
		{Name: "ID", OID: ignoredOID},
		{Name: "ScreenshotID", OID: ignoredOID},
		{Name: "Index", OID: ignoredOID},
		{Name: "MinX", OID: ignoredOID},
		{Name: "MinY", OID: ignoredOID},
		{Name: "MaxX", OID: ignoredOID},
		{Name: "MaxY", OID: ignoredOID},
		{Name: "Body", OID: ignoredOID},
	}, []pgtype.ValueTranscoder{
		&pgtype.Int4{},
		&pgtype.Int8{},
		&pgtype.Int2{},
		&pgtype.Int2{},
		&pgtype.Int2{},
		&pgtype.Int2{},
		&pgtype.Int2{},
		&pgtype.Text{},
	})
	blocksArray := pgtype.NewArrayType("_blocks", ignoredOID, func() pgtype.ValueTranscoder {
		return blocksRow.NewTypeValue().(*pgtype.CompositeType)
	})
	for rows.Next() {
		var item SearchScreenshotsRow
		if err := rows.Scan(&item.ID, &item.Timestamp, &item.DirectoryAlias, &item.Filename, &item.DimWidth, &item.DimHeight, &item.DominantColour, &item.Blurhash, blocksArray, &item.Similarity); err != nil {
			return nil, fmt.Errorf("scan SearchScreenshots row: %w", err)
		}
		blocksArray.AssignTo(&item.Blocks)
		items = append(items, item)
	}
	if err := rows.Err(); err != nil {
		return nil, fmt.Errorf("close SearchScreenshots rows: %w", err)
	}
	return items, err
}

// SearchScreenshotsBatch implements Querier.SearchScreenshotsBatch.
func (q *DBQuerier) SearchScreenshotsBatch(batch *pgx.Batch, params SearchScreenshotsParams) {
	batch.Queue(searchScreenshotsSQL, params.Body, params.Limit, params.Offset)
}

// SearchScreenshotsScan implements Querier.SearchScreenshotsScan.
func (q *DBQuerier) SearchScreenshotsScan(results pgx.BatchResults) ([]SearchScreenshotsRow, error) {
	rows, err := results.Query()
	if err != nil {
		return nil, fmt.Errorf("query SearchScreenshotsBatch: %w", err)
	}
	defer rows.Close()
	items := []SearchScreenshotsRow{}
	blocksRow, _ := pgtype.NewCompositeTypeValues("blocks", []pgtype.CompositeTypeField{
		{Name: "ID", OID: ignoredOID},
		{Name: "ScreenshotID", OID: ignoredOID},
		{Name: "Index", OID: ignoredOID},
		{Name: "MinX", OID: ignoredOID},
		{Name: "MinY", OID: ignoredOID},
		{Name: "MaxX", OID: ignoredOID},
		{Name: "MaxY", OID: ignoredOID},
		{Name: "Body", OID: ignoredOID},
	}, []pgtype.ValueTranscoder{
		&pgtype.Int4{},
		&pgtype.Int8{},
		&pgtype.Int2{},
		&pgtype.Int2{},
		&pgtype.Int2{},
		&pgtype.Int2{},
		&pgtype.Int2{},
		&pgtype.Text{},
	})
	blocksArray := pgtype.NewArrayType("_blocks", ignoredOID, func() pgtype.ValueTranscoder {
		return blocksRow.NewTypeValue().(*pgtype.CompositeType)
	})
	for rows.Next() {
		var item SearchScreenshotsRow
		if err := rows.Scan(&item.ID, &item.Timestamp, &item.DirectoryAlias, &item.Filename, &item.DimWidth, &item.DimHeight, &item.DominantColour, &item.Blurhash, blocksArray, &item.Similarity); err != nil {
			return nil, fmt.Errorf("scan SearchScreenshotsBatch row: %w", err)
		}
		blocksArray.AssignTo(&item.Blocks)
		items = append(items, item)
	}
	if err := rows.Err(); err != nil {
		return nil, fmt.Errorf("close SearchScreenshotsBatch rows: %w", err)
	}
	return items, err
}
